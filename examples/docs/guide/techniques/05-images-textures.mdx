import { FragmentEditor } from '@site/src/theme/FragmentEditor'

# Images and Textures

Learn how to load and process external images, and techniques for texture-based expressions.

## Loading Images

### Basic Image Loading

<FragmentEditor
        isFun
        code={`
const fragment = () => {
        const iTexture = uniform('https://avatars.githubusercontent.com/u/40712342')
        const uv = position.xy.div(iResolution) // Calculate correct UV coordinates
        // Get pixel color from texture
        const textureColor = texture(iTexture, uv)
        return textureColor
}`}
/>

### Understanding UV Coordinates

UV coordinates are a coordinate system that represents positions on an image:

```
(0,1) -------- (1,1)
  |              |
  |     Image    |
  |              |
(0,0) -------- (1,0)
```

<FragmentEditor
        isFun
        code={`
const fragment = () => {
        const uvColor = vec4(uv.x, uv.y, 0, 1)
        return uvColor
}`}
/>

## Image Filters

### Blur Effect

<FragmentEditor
        isFun
        code={`
const fragment = () => {
        const iTexture = uniform('https://avatars.githubusercontent.com/u/40712342')
        const blurFilter = Fn(([uv, blurRadius, size]) => {
                let blurColor = vec4(0).toVar()
                let totalWeight = float(0).toVar()
                const pixelSize = vec2(float(1)).div(iResolution)
                const halfSize = size.div(float(2)).toVar()
                const totalSamples = int(size.mul(size))
                // Dynamic sampling based on size parameter
                Loop(totalSamples, ({ i }) => {
                        const x = mod(float(i), size).sub(halfSize)
                        const y = floor(float(i).div(size)).sub(halfSize)
                        // Calculate distance from center for weight
                        const dist = length(vec2(x, y))
                        const weight = exp(dist.mul(dist).mul(float(-0.5)))
                        // Sample offset
                        const offset = vec2(x, y).mul(pixelSize).mul(blurRadius)
                        const sampleUV = uv.add(offset)
                        // Clamp UV coordinates to prevent artifacts
                        const clampedUV = clamp(sampleUV, vec2(0), vec2(1))
                        const sampleColor = texture(iTexture, clampedUV)
                        blurColor.assign(blurColor.add(sampleColor.mul(weight)))
                        totalWeight.assign(totalWeight.add(weight))
                })
                // Normalize by total weight
                return blurColor.div(totalWeight)
        })
        // Apply blur filter
        return blurFilter(uv, 2, 4)
}`}
/>

### Edge Detection

<FragmentEditor
        isFun
        code={`
const fragment = () => {
        const iTexture = uniform('https://avatars.githubusercontent.com/u/40712342')
        const step = vec2(1).div(iResolution)
        // Sample 3x3 neighborhood as vectors
        const s = (x, y) => texture(iTexture, uv.add(vec2(x, y).mul(step))).r
        const row1 = vec3(s(-1, -1), s(0, -1), s(1, -1))
        const row2 = vec3(s(-1, 0),  s(0, 0),  s(1, 0))
        const row3 = vec3(s(-1, 1),  s(0, 1),  s(1, 1))
        // Sobel X kernel
        const kx1 = vec3(-1, 0, 1)
        const kx2 = vec3(-2, 0, 2)
        const kx3 = vec3(-1, 0, 1)
        // Sobel Y kernel
        const ky1 = vec3(-1, -2, -1)
        const ky2 = vec3(0, 0, 0)
        const ky3 = vec3(1, 2, 1)
        // Matrix convolution using dot products
        const gx = dot(row1, kx1).add(dot(row2, kx2)).add(dot(row3, kx3))
        const gy = dot(row1, ky1).add(dot(row2, ky2)).add(dot(row3, ky3))
        const edge = length(vec2(gx, gy))
        return vec4(vec3(edge), 1)
}`}
/>

### Sepia Tone

<FragmentEditor
        isFun
        code={`
const fragment = () => {
        const iTexture = uniform('https://avatars.githubusercontent.com/u/40712342')
        const originalColor = texture(iTexture, uv)
        // Sepia tone conversion matrix
        const sepiaR = originalColor.r
                .mul(float(0.393))
                .add(originalColor.g.mul(float(0.769)))
                .add(originalColor.b.mul(float(0.189)))
        const sepiaG = originalColor.r
                .mul(float(0.349))
                .add(originalColor.g.mul(float(0.686)))
                .add(originalColor.b.mul(float(0.168)))
        const sepiaB = originalColor.r
                .mul(float(0.272))
                .add(originalColor.g.mul(float(0.534)))
                .add(originalColor.b.mul(float(0.131)))
        return vec4(sepiaR, sepiaG, sepiaB, originalColor.a)
}`}
/>

## Texture Coordinate

### Texture Tiling

<FragmentEditor
        isFun
        code={`
const fragment = () => {
        const iTexture = uniform('https://avatars.githubusercontent.com/u/40712342')
        // Scale coordinates and repeat
        const scale = float(3)
        const repeatedUV = fract(uv.mul(scale))
        return texture(iTexture, repeatedUV)
}`}
/>

### Texture Rotation

<FragmentEditor
        isFun
        code={`
const fragment = () => {
        const iTexture = uniform('https://avatars.githubusercontent.com/u/40712342')
        // Center coordinates (-0.5 to 0.5)
        const centeredUV = uv.sub(vec2(0.5))
        // Rotation
        const angle = iTime.mul(float(0.5))
        const cosA = cos(angle)
        const sinA = sin(angle)
        const rotatedUV = vec2(
                centeredUV.x.mul(cosA).sub(centeredUV.y.mul(sinA)),
                centeredUV.x.mul(sinA).add(centeredUV.y.mul(cosA))
        ).add(0.5)
        // Wrap out-of-bounds to repeat
        const wrappedUV = fract(rotatedUV)
        return texture(iTexture, wrappedUV)
}`}
/>

### Fisheye Lens

<FragmentEditor
        isFun
        code={`
const fragment = () => {
        const iTexture = uniform('https://avatars.githubusercontent.com/u/40712342')
        // Center UV coordinates around (0,0)
        const centeredUV = uv.sub(vec2(0.5)).mul(2.0)
        const radius = length(centeredUV)
        // Fisheye distortion - barrel distortion effect
        const strength = float(0.5) // Reduced distortion strength
        const distortedRadius = radius.mul(oneMinus(strength.mul(radius.mul(radius))))
        // Calculate new UV coordinates
        const newUV = centeredUV.mul(distortedRadius.div(radius)).div(2.0).add(0.5)
        // Sample texture with clamped coordinates to avoid black edges
        const clampedUV = clamp(newUV, vec2(0.0), vec2(1.0))
        return texture(iTexture, clampedUV)
}`}
/>

## Dynamic Texture

### Texture Scrolling

<FragmentEditor
        isFun
        code={`
const fragment = () => {
        const iTexture = uniform('https://avatars.githubusercontent.com/u/40712342')
        // Scroll speed
        const scrollSpeed = vec2(float(0.1), float(0.05))
        // Time-based offset
        const offset = iTime.mul(scrollSpeed)
        return texture(iTexture, fract(uv.add(offset)))
}`}
/>

### Wavy Texture

<FragmentEditor
        isFun
        code={`
const fragment = () => {
        const iTexture = uniform('https://avatars.githubusercontent.com/u/40712342')
        // Create wave distortion as vec2
        const wavy = Fn(([amplitude, frequency, speed]) => {
                return sin(uv.yx.mul(frequency).add(iTime.mul(speed))).mul(amplitude)
        })
        // Apply wave distortion to UV coordinates
        const wavyUV = uv.add(wavy(0.1, 16, 4))
        return texture(iTexture, wavyUV)
}`}
/>

### Particle Texture

<FragmentEditor
        isFun
        code={`
const fragment = () => {
        const iTexture = uniform('https://avatars.githubusercontent.com/u/40712342')
        // Particle texture effect using Loop for efficient layering
        const generateParticleLayers = Fn(([uv]) => {
                const finalColor = vec4(0, 0, 0, 0).toVar()
                // Generate multiple particle layers using Loop
                Loop(int(4), ({ i }) => {
                        const layerIndex = float(i)
                        // Calculate layer properties based on index
                        const speedBase = layerIndex.mul(0.08).add(0.05)
                        const speed = vec2(speedBase, speedBase.mul(0.6))
                        const scale = layerIndex.mul(1.5).add(1.5)
                        // Calculate layer offset and UV
                        const offset = iTime.mul(speed)
                        const layerUV = fract(uv.mul(scale).add(offset))
                        // Sample texture for this layer
                        const layerColor = texture(iTexture, layerUV)
                        // Calculate alpha based on layer depth
                        const alpha = float(0.3).add(layerIndex.mul(0.1))
                        // Accumulate layers
                        finalColor.assign(finalColor.add(layerColor.mul(alpha)))
                })
                return finalColor
        })
        return generateParticleLayers(uv, iTime)
}`}
/>

## Advanced Texture

### Pattern Blending

Combine procedural patterns with texture sampling for complex effects:

<FragmentEditor
        isFun
        code={`
const fragment = () => {
        const iTexture = uniform('https://avatars.githubusercontent.com/u/40712342')
        // Procedural checker mask
        const checker = mod(floor(uv.x.mul(8)).add(floor(uv.y.mul(8))), 2.0)
        // Simple procedural overlay
        const noise = sin(uv.x.mul(20)).mul(sin(uv.y.mul(20))).mul(0.5).add(0.5)
        const overlayColor = vec4(noise.mul(0.8).add(0.2), noise.mul(0.6).add(0.4), noise, 1.0)
        // Blend with texture
        const baseColor = texture(iTexture, uv)
        return mix(baseColor, overlayColor, checker)
}`}
/>

### Pattern Control

Use texture data to control procedural pattern parameters:

<FragmentEditor
        isFun
        code={`
const fragment = () => {
        const sourceTexture = uniform('https://avatars.githubusercontent.com/u/40712342')
        // Sample texture for generative parameters
        const texData = texture(sourceTexture, uv.mul(0.2))
        const flow = texData.r.mul(iTime.mul(0.2))
        const freq = texData.g.mul(15.0).add(5.0)
        // Create generative pattern driven by texture
        const pattern = sin(uv.x.mul(freq).add(flow))
                .mul(cos(uv.y.mul(freq).add(flow)))
                .add(sin(length(uv.sub(0.5)).mul(10.0).sub(iTime)))
        // Blend original texture with subtle pattern overlay
        const originalColor = texture(sourceTexture, uv)
        const patternOverlay = pattern.mul(0.3).add(0.7)
        const color = originalColor.rgb.mul(patternOverlay)
        return vec4(color, 1.0)
}`}
/>

### Dynamic Distortion

Use texture data to drive animation parameters and create dynamic effects:

<FragmentEditor
        isFun
        code={`
const fragment = () => {
        const iTexture = uniform('https://avatars.githubusercontent.com/u/40712342')
        // Generate procedural noise for animation data
        const noise = Fn(([uv]) => {
                const n1 = sin(uv.x.mul(10)).mul(sin(uv.y.mul(10)))
                const n2 = sin(uv.x.mul(20).add(uv.y.mul(15))).mul(0.5)
                return n1.add(n2).mul(0.5).add(0.5)
        })
        // Sample texture to get base noise value
        const baseColor = texture(iTexture, uv)
        const textureNoise = baseColor.r.add(baseColor.g).add(baseColor.b).div(3.0)
        // Combine texture-based and procedural noise
        const proceduralNoise = noise(uv.mul(0.5))
        const combinedNoise = mix(textureNoise, proceduralNoise, 0.5)
        // Use combined noise to modulate time-based animation
        const animSpeed = combinedNoise.mul(2.0).add(0.5)
        const animOffset = sin(iTime.mul(animSpeed)).mul(0.08)
        // Create texture-driven distortion
        const distortedUV = uv.add(vec2(
                animOffset.mul(cos(combinedNoise.mul(6.28))),
                animOffset.mul(sin(combinedNoise.mul(6.28)))
        ))
        // Sample texture with distorted coordinates
        const finalColor = texture(iTexture, distortedUV)
        // Apply color modulation based on texture data
        const colorShift = combinedNoise.mul(0.2)
        return vec4(
                finalColor.r.add(colorShift),
                finalColor.g.mul(oneMinus(colorShift.mul(0.5))),
                finalColor.b.sub(colorShift.mul(0.3)),
                finalColor.a
        )
}`}
/>

## Next Steps

Once you've mastered image and texture manipulation, next learn about [Interactive Effects](06-interactive-effects.md) to create effects that respond to user interactions.

What you learned in this tutorial:

- ✅ Image loading and UV coordinates
- ✅ Image filters (blur, edge detection, sepia)
- ✅ Texture coordinate manipulation
- ✅ Dynamic texture effects
- ✅ Procedural texture creation

In the next chapter, you'll learn about interactive visual expressions that respond to mouse and keyboard operations.
